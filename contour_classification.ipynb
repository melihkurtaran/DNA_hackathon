{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGCvoQYA+ztrB1hgLeVr97",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melihkurtaran/DNA_hackathon/blob/main/Classifiacation_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the images\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary',\n",
        "                                                 classes = ['NOISE', 'CLOUD'])\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary',\n",
        "                                            classes = ['NOISE', 'CLOUD'],\n",
        "                                            shuffle = False)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units = 128, activation = 'sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(training_set, epochs = 10, validation_data = test_set)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_set, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBZKx_JCjkaY",
        "outputId": "a64905fe-18b4-4c2f-c12a-0ea12373b385"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 560 images belonging to 2 classes.\n",
            "Found 560 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 4s 173ms/step - loss: 0.5999 - accuracy: 0.7196 - val_loss: 0.5985 - val_accuracy: 0.7196\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 211ms/step - loss: 0.6048 - accuracy: 0.7196 - val_loss: 0.5940 - val_accuracy: 0.7196\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 3s 160ms/step - loss: 0.5883 - accuracy: 0.7214 - val_loss: 0.5718 - val_accuracy: 0.7268\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 3s 163ms/step - loss: 0.5906 - accuracy: 0.7232 - val_loss: 0.5664 - val_accuracy: 0.7357\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 3s 160ms/step - loss: 0.5753 - accuracy: 0.7250 - val_loss: 0.5491 - val_accuracy: 0.7339\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 3s 161ms/step - loss: 0.5568 - accuracy: 0.7357 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 4s 209ms/step - loss: 0.5568 - accuracy: 0.7411 - val_loss: 0.5257 - val_accuracy: 0.7536\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 3s 158ms/step - loss: 0.5535 - accuracy: 0.7429 - val_loss: 0.5203 - val_accuracy: 0.7589\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 4s 242ms/step - loss: 0.5592 - accuracy: 0.7321 - val_loss: 0.5196 - val_accuracy: 0.7571\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 3s 161ms/step - loss: 0.5530 - accuracy: 0.7411 - val_loss: 0.5309 - val_accuracy: 0.7643\n",
            "18/18 - 1s - loss: 0.5309 - accuracy: 0.7643 - 797ms/epoch - 44ms/step\n",
            "\n",
            "Test accuracy: 0.7642857432365417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noise example"
      ],
      "metadata": {
        "id": "ae1RJEG4l_cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img('/content/NOISE/cont_2.jpg', target_size = (64, 64))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis = 0)\n",
        "img = img / 255.0\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(img)\n",
        "\n",
        "# Check the result\n",
        "if prediction[0][0] > 0.5:\n",
        "    print('The image is classified as Cloud')\n",
        "else:\n",
        "    print('The image is classified as Noise')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfSoqaFskPe_",
        "outputId": "0a2adeed-aaff-4544-b0ea-f826b71ed34d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n",
            "The image is classified as Noise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img('/content/NOISE/cont_2.jpg', target_size = (64, 64))\n",
        "img = image.img_to_array(img)\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(img / 255.0)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "-4jCs18Gkd0Z",
        "outputId": "1578e41e-8892-4dd1-e752-4fd868790340"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAEYUlEQVR4nO3dTU4UWxiA4Sp1ZAxxRvxjwIA1qCtwCY7djstwE44dsAUTGeEPcehYI+Wsblff1tzbCLwdnmf0wWnlaPKmz4FUGKdpGoCeW9e9AWAzcUKUOCFKnBAlToi686fFcRx9Kxcu2TRN46bPe+eEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFC1J1t/+A4jhvnYRiG8/Pz7XcEDMPgnROyxAlRWx9rb936p+vT09PF2u3bt+f54OBgnvf39xev+/z58zyvH42nadr4tRyZuSm8c0KUOCFKnBA1rt7t/rU4jr9fXL5u8fHjx4/n+eXLl/P8+vXrxetevHgxz2/fvl2sffjwYZ6Pjo7+yzZgJ03TNG76vHdOiBInRG19rD05OZnne/fuLdYePHhw8Y2tHJVXf+Ty9OnTxes+ffp04a8F18mxFnaMOCFKnBD1V36Usu7jx4/z/OrVq3lev4u+efPmt3/H8+fP5/n4+Hie1/d7dnY2z48ePVqsrd5b//TvhOvkzgk7RpwQdSnH2t9ZfbpkGJZPszx58mSx9uXLl3leP66uWl3b29tbrL1//36rfcJVcqyFHSNOiBInRF3pnfNvWH8C5uvXr/P88+fPxdrDhw+vZE9wEe6csGPECVE7d6z9G9afZDk8PJznHz9+XPV2uOEca2HHiBOibuSxdv07vs+ePZvnu3fvLtbevXs3z9+/f7/cjXEjOdbCjhEnRIkTom7knXNbq0/KDMPy98Cs/j/6fS78H+6csGPECVGOtZfg27dvi4/v378/z+sPnDsC41gLO0acECVOiHLnhGvmzgk7RpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocULUOE3Tde8B2MA7J0SJE6LECVHihChxQpQ4IeoXbweuot5rdyEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloud example"
      ],
      "metadata": {
        "id": "fHd9x5LxmA6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img('/content/CLOUD/cont_0.jpg', target_size = (64, 64))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis = 0)\n",
        "img = img / 255.0\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(img)\n",
        "\n",
        "# Check the result\n",
        "if prediction[0][0] > 0.5:\n",
        "    print('The image is classified as Cloud')\n",
        "else:\n",
        "    print('The image is classified as Noise')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwRrRuRLkvL3",
        "outputId": "abdee612-f211-499f-f93a-5afd6e6ab7bb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "The image is classified as Cloud\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img('/content/CLOUD/cont_0.jpg', target_size = (64, 64))\n",
        "img = image.img_to_array(img)\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(img / 255.0)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "FIc3AG9DmDoy",
        "outputId": "98b65890-57d7-42a3-c617-e819b158d5d8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
